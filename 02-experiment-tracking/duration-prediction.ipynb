{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bd82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3887656-72cf-4a42-924e-8238eeb1ca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/MLOP-zoomcamps/02-experiment-tracking\n"
     ]
    }
   ],
   "source": [
    "cd ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41062d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c984c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4add538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b135c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1464985f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/29 11:54:42 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/11/29 11:54:42 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2025-11-29 11:54:42 INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2025-11-29 11:54:42 INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "2025-11-29 11:54:42 INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2025-11-29 11:54:42 INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "2025-11-29 11:54:43 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025/11/29 11:54:43 INFO mlflow.tracking.fluent: Experiment with name 'nyc-taxi-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/MLOP-zoomcamps/02-experiment-tracking/mlruns/1', creation_time=1764417283427, experiment_id='1', last_update_time=1764417283427, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e6479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8029eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('./data/green_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('./data/green_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f2f0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73908, 61921)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "951d51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5cbfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e9fb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "429e2394",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m lr.fit(X_train, y_train)\n\u001b[32m      4\u001b[39m y_pred = lr.predict(X_val)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:196\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m params.apply_defaults()\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/inspect.py:3242\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3238\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3239\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3240\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3241\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/inspect.py:3231\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3229\u001b[39m         arguments[kwargs_param.name] = kwargs\n\u001b[32m   3230\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3231\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3232\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3233\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/lin_reg.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, lr), f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4999b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    mlflow.set_tag(\"developer\", \"cristian\")\n",
    "\n",
    "    mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2021-01.csv\")\n",
    "    mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2021-02.csv\")\n",
    "\n",
    "    alpha = 0.1\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    lr = Lasso(alpha)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    mlflow.log_artifact(local_path=\"models/lin_reg.bin\", artifact_path=\"models_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0eb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907dc6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ab328",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d84b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cd729",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    best_params = {\n",
    "        'learning_rate': 0.09585355369315604,\n",
    "        'max_depth': 30,\n",
    "        'min_child_weight': 1.060597050922164,\n",
    "        'objective': 'reg:linear',\n",
    "        'reg_alpha': 0.018060244040060163,\n",
    "        'reg_lambda': 0.011658731377413597,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    mlflow.xgboost.log_model(booster, artifact_path=\"models_mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2108f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87614b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "for model_class in (RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, LinearSVR):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2021-01.csv\")\n",
    "        mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2021-02.csv\")\n",
    "        mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "        mlmodel = model_class()\n",
    "        mlmodel.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = mlmodel.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0813c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c489ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
